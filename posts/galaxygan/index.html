<!DOCTYPE html><html lang="en-US" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="GalaxyGAN" /><meta property="og:locale" content="en_US" /><meta name="description" content="GalaxyGAN" /><meta property="og:description" content="GalaxyGAN" /><link rel="canonical" href="https://inzombakura.github.io/posts/galaxygan/" /><meta property="og:url" content="https://inzombakura.github.io/posts/galaxygan/" /><meta property="og:site_name" content="Inzombakura" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-12-11T23:12:11-08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="GalaxyGAN" /><meta name="twitter:site" content="@inzombakura" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-12-14T19:01:47-08:00","datePublished":"2021-12-11T23:12:11-08:00","description":"GalaxyGAN","headline":"GalaxyGAN","mainEntityOfPage":{"@type":"WebPage","@id":"https://inzombakura.github.io/posts/galaxygan/"},"url":"https://inzombakura.github.io/posts/galaxygan/"}</script><title>GalaxyGAN | Inzombakura</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Inzombakura"><meta name="application-name" content="Inzombakura"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://avatars.githubusercontent.com/u/68891952?v=4" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Inzombakura</a></div><div class="site-subtitle font-italic">Powered by getting enough sleep</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/inzombakura" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/inzombakura" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['amousavi','cs.washington.edu'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>GalaxyGAN</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>GalaxyGAN</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Armand Mousavi </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sat, Dec 11, 2021, 11:12 PM -0800" >Dec 11, 2021<i class="unloaded">2021-12-11T23:12:11-08:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Tue, Dec 14, 2021, 7:01 PM -0800" >Dec 14, 2021<i class="unloaded">2021-12-14T19:01:47-08:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1505 words">8 min read</span></div></div><div class="post-content"><h1 id="galaxygan">GalaxyGAN</h1><p><em>Created by: Armand Mousavi, Karman Singh, and Matthew Foss</em></p><p><em>UW student project for CSE490G1</em></p><p><a href="https://colab.research.google.com/drive/1hmF0jklxkFRqLjqfthI5kmf2GB_bqQfk?usp=sharing">Try the demo out for yourself</a></p><h2 id="video">Video</h2><p><a href="https://youtu.be/pWN0kjnHRRs" title="Galaxy GAN"><img data-proofer-ignore data-src="http://img.youtube.com/vi/pWN0kjnHRRs/0.jpg" alt="Galxy GAN video demo" /></a></p><h2 id="abstractbackground">Abstract/Background</h2><p>A Generative Adversarial Network can be broken down into three parts: learn a generative model, train a model in an adversarial setting, and use deep neural networks. In a GAN there is the generator and the discriminator. The Generator creates fake images to input into the discriminator. The discriminator takes two images, one real and one fake. The discriminator’s job is to decide whether the image is fake or real. The generative model tries to maximize the probability of fooling the discriminator while the discriminator tries to maximize the probability of the sample being from the real dataset. Pictured below is a basic representation of a GAN, credit from</p><p><img data-proofer-ignore data-src="https://www.researchgate.net/profile/Murat-Kuzlu/publication/350092575/figure/fig1/AS:1002719980580864@1616078481497/The-basic-structure-of-the-generative-adversarial-network-GAN-model.jpg" alt="enter image description here" /> <a href="https://www.researchgate.net/figure/The-basic-structure-of-the-generative-adversarial-network-GAN-model_fig1_350092575">source</a></p><p>The GalaxyGAN implementation follows this methodology. GalaxyGAN was designed to create fake images to fool the discriminator.</p><h2 id="problem-statement">Problem statement</h2><p>We want to see if we can use a Generative Adversarial Network to produce new images of fake galaxies using a comprehensive dataset of colored galaxy images and do it in a way that we didn’t have to train the model for more than a couple days.</p><h2 id="related-work">Related work</h2><p>We talked about using GAN and the best ways to utilize this network. We searched many different websites with datasets. The dataset we used was a relatively large set of galaxy images called Galaxy10 DECals from this <a href="https://astronn.readthedocs.io/en/latest/galaxy10.html">website</a>. The Galaxy10 DECals is an improved version of Galaxy10. The Galaxy10 dataset was created with the Galaxy Zoo data release where volunteers classified around 270K of Sloan Digital Sky Survey, SDSS, galaxy images. GZ later utilized DESI Legacy Imaging Surveys to create the new and improved version Galaxy10 DECals.</p><p><strong>Galaxy10 dataset (17736 images)</strong></p><blockquote><ul><li>Class 0 (1081 images): Disturbed Galaxies<li>Class 1 (1853 images): Merging Galaxies<li>Class 2 (2645 images): Round Smooth Galaxies<li>Class 3 (2027 images): In-between Round Smooth Galaxies<li>Class 4 ( 334 images): Cigar Shaped Smooth Galaxies<li>Class 5 (2043 images): Barred Spiral Galaxies<li>Class 6 (1829 images): Unbarred Tight Spiral Galaxies<li>Class 7 (2628 images): Unbarred Loose Spiral Galaxies<li>Class 8 (1423 images): Edge-on Galaxies without Bulge<li>Class 9 (1873 images): Edge-on Galaxies with Bulge</ul></blockquote><p><img data-proofer-ignore data-src="https://astronn.readthedocs.io/en/latest/_images/galaxy10_example.png" alt="enter image description here" /></p><h2 id="methodology">Methodology</h2><p>We referred to the tutorials for guidance from <a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">here</a> and from <a href="https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch/">here</a>.</p><p>Before working with the data for the final model we downsized all of the images from the original dataset. The 256x256 images required a larger model that took an extreme amount of time to train on and more RAM than we had available on colab to comfortably work with.</p><p>We first define the discriminator model, which needs to take a sample image from our dataset as input and output a classification prediction as to whether the sample is real or fake. The inputs are three color channels and 128 by 128 pixels in size. The model has a normal convolutional layer followed by five convolutional layers using a stride of 2 by 2 to downsample the input image. The model has no pooling layers and a single node in the output layer with the sigmoid activation function to predict whether the input sample is real or fake. The model is trained to minimize the binary cross entropy loss function, which is suitable for binary classification. We use the industry best practice with the LeakyReLU instead of ReLU, and the Adam version of stochastic gradient descent with a learning rate of 0.0002 and a momentum of 0.5</p><p>The generator model is responsible for creating new, but fake images and does this by taking a point from the latent space as input and outputting a square color image. We don’t want just one low-resolution version of the image, but many parallel interpretations of the input. So, the first hidden layer, the Dense layer, needs enough nodes for multiple versions of the output image, such as 256. The activations from these nodes can be reshaped into an image shape to pass into the convolutional layer, such as 256 different 4 by 4 feature maps. Now we need to upsample the low-resolution image to a higher resolution version of the image. We will use Conv2DTranspose to reverse pool and convolute. We configure the Conv2DTranspose layer with stride of 2 by 2 and quadruple the area of the input feature maps by doubling the width and height. We up sample five times to reach the required output image size of 128 by 128. We use the LeakyReLU activation function again as best practice for training GAN models. The output layer of the model is a Conv2D with three filters for the required three channels and kernel size of 3 by 3. Finally a tanh activation is used to ensure the output values are in the range [-1, 1].</p><p>For generating real samples, we will just take the training dataset and select a random subsample of images. We need to generate new points in the latent space and the array of random numbers then reshape into samples, which are then used as input to the generator model. We need to generate images composed of random pixel values for the generate fake samples function, which takes in the generator model as an argument.</p><p>Here you can see the full model for the discriminator:</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/discriminator_model.png" alt="discriminator model" /></p><p>As well as the model for the generator:</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/generator_model.png" alt="generator model" /></p><h2 id="experimentsevaluation">Experiments/evaluation</h2><p>You can check out our final notebook we used to train our model <a href="https://colab.research.google.com/drive/1RdZdxvGyW6IsrBFrSRiOPHKKFHeap86g?usp=sharing">here</a></p><p>When evaluating the Generative Adversarial Network, there isn’t really an objective error score for the generated images. The images will need to subjectively be evaluated. Also the adversarial nature of the training means the generator is changing after each batch and the subjective quality of the images may improve or degrade with further updates. To handle this, first we periodically evaluate the classification accuracy of the discriminator on real and fake images, second we periodically generate many images and save them for review, and third we periodically save the generator model. If we train the GAN over many epochs, we would be able to get many snapshots of the model and choose the best models, once reviewed for performance.</p><p>We define a function for summarizing the performance of the discriminator model. This function takes a sample of real galaxy images and generates the same number of fake galaxy images with the generator model and then evaluates the classification accuracy of the discriminator model and reports the score for each sample.</p><p>This is an example of the loss values on real images and fake generated images for the discriminator and the generator for epoch 26</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span text-data=" Plaintext "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>&gt;26, 1/138, d1=0.29638204, d2=0.32488263 g=3.45844007
&gt;26, 2/138, d1=0.45061448, d2=0.88800186 g=4.71526003
&gt;26, 3/138, d1=1.16259015, d2=0.06006718 g=4.13229275
&gt;26, 4/138, d1=0.72051704, d2=0.09301022 g=2.78597784
&gt;26, 5/138, d1=0.81719440, d2=0.22286285 g=2.34299660 … … …
&gt;26, 134/138, d1=1.59510779, d2=0.09820783 g=2.37885666
&gt;26, 135/138, d1=0.35758907, d2=0.54601729 g=2.40457916
&gt;26, 136/138, d1=0.22124308, d2=0.10850765 g=2.61518002
&gt;26, 137/138, d1=0.18373565, d2=0.13180479 g=2.34858227
&gt;26, 138/138, d1=0.02594333, d2=0.20959115 g=2.79657221
</pre></table></code></div></div><p>This is an example of the model’s accuracy score for epoch 26 based on the discriminators ability to differentiate</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span text-data=" Plaintext "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&gt;Accuracy real: 94%, fake: 100%
</pre></table></code></div></div><p>This is an example of the image produced by the model for epoch 26</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e26.png" alt="epoch 26" /></p><h2 id="results">Results</h2><p>Epoch 11</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e11.png" alt="epoch 11" /></p><p>Epoch 12</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e12.png" alt="epoch 12" /></p><p>Epoch 13</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e13.png" alt="epoch 13" /></p><p>Epoch 14</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e14.png" alt="epoch 14" /></p><p>Epoch 15</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e15.png" alt="epoch 15" /></p><p>The results after the first training process for 15 epochs yielded the following results and we can see that the quality of the images are not consecutively increasing and from my understanding, Epoch 13 out of the last five epochs had the best result with the least amount of noise in comparison to the colorful galaxy center. At this stage the galaxy isn’t very detailed and more like a cloud of color, with a ton of noise and repetition of small sections, introducing patterns.</p><p>Epoch 41</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e41.png" alt="epoch 41" /></p><p>Epoch 42</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e42.png" alt="epoch 42" /></p><p>Epoch 43</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e43.png" alt="epoch 43" /></p><p>Epoch 44</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e44.png" alt="epoch 44" /></p><p>And finally… Epoch 45</p><p><img data-proofer-ignore data-src="https://raw.githubusercontent.com/inzombakura/inzombakura.github.io/main/assets/img/galaxygan_e45.png" alt="epoch 45" /></p><p>These are the results after the second training process for an additional 35 epochs. We can see that the quality does get better and there is more detail but we can see issues with repeated patterns in Epoch 41 and 42. The last three are fairly good representations of galaxies, where Epoch 43 has a very clean image, with a detailed galaxy center with little outside noise. Epoch 44 has a bit of a problem with the patterns of the outside of the galaxy with the red spots but the galaxy center is really rich in color and detail. Epoch 45 is the combination of the last two, where the center is colorful and clear and the surrounding is pretty clean with minimal noise.</p><h2 id="final-thoughts">Final Thoughts</h2><p>With more time we would definitely continue training this network, maybe on some persistent computer for at least a week. This would also allow us to attempt to generate original sized images at 256x256. It would also be wise for us to try new models like to add batch normalization layers to the layers of the discriminator which is quite easy with keras.</p><p>Thank you again to the whole team and to you for reading our report.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/projects/'>Projects</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/python/" class="post-tag no-text-decoration" >python</a> <a href="/tags/keras/" class="post-tag no-text-decoration" >keras</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=GalaxyGAN - Inzombakura&url=https://inzombakura.github.io/posts/galaxygan/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=GalaxyGAN - Inzombakura&u=https://inzombakura.github.io/posts/galaxygan/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=GalaxyGAN - Inzombakura&url=https://inzombakura.github.io/posts/galaxygan/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/breed-id/">Dog Breed Identification Using Neural Networks</a><li><a href="/posts/galaxygan/">GalaxyGAN</a><li><a href="/posts/trash-identification/">Trash Material Identifier</a><li><a href="/posts/drawing-with-light/">Drawing With Light</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/javascript/">javascript</a> <a class="post-tag" href="/tags/canvas/">canvas</a> <a class="post-tag" href="/tags/colab/">colab</a> <a class="post-tag" href="/tags/cv/">CV</a> <a class="post-tag" href="/tags/fastai/">fastai</a> <a class="post-tag" href="/tags/flask/">flask</a> <a class="post-tag" href="/tags/htb/">htb</a> <a class="post-tag" href="/tags/keras/">keras</a> <a class="post-tag" href="/tags/ml/">ML</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/trash-identification/"><div class="card-body"> <span class="timeago small" >Aug 28, 2021<i class="unloaded">2021-08-28T14:09:30-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Trash Material Identifier</h3><div class="text-muted small"><p> Garbage is everywhere. One of the major annoyances we all face when dealing with it is correctly sorting it into it’s proper categories and receptacles. A strong goal for the future is to automat...</p></div></div></a></div><div class="card"> <a href="/posts/breed-id/"><div class="card-body"> <span class="timeago small" >Jun 3<i class="unloaded">2022-06-03T00:12:11-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Dog Breed Identification Using Neural Networks</h3><div class="text-muted small"><p> Created by: Armand Mousavi (amousavi@cs), Vivek Patel (vivekp@cs), and Albert Zhong (azhong@cs) UW student project for CSE455 22sp Video Abstract and Background FGIC (Fine-Grained Image Class...</p></div></div></a></div><div class="card"> <a href="/posts/drawing-with-light/"><div class="card-body"> <span class="timeago small" >Aug 22, 2021<i class="unloaded">2021-08-22T10:09:30-07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Drawing With Light</h3><div class="text-muted small"><p> This weekend I worked on a way of drawing on the HTML5 canvas that would simulate what it would be like to draw with a flashlight on a 2D plane. Written purely in javascript, you can try out the ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/trash-identification/" class="btn btn-outline-primary" prompt="Older"><p>Trash Material Identifier</p></a> <a href="/posts/breed-id/" class="btn btn-outline-primary" prompt="Newer"><p>Dog Breed Identification Using Neural Networks</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/inzombakura">Armand Mousavi</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/javascript/">javascript</a> <a class="post-tag" href="/tags/canvas/">canvas</a> <a class="post-tag" href="/tags/colab/">colab</a> <a class="post-tag" href="/tags/cv/">CV</a> <a class="post-tag" href="/tags/fastai/">fastai</a> <a class="post-tag" href="/tags/flask/">flask</a> <a class="post-tag" href="/tags/htb/">htb</a> <a class="post-tag" href="/tags/keras/">keras</a> <a class="post-tag" href="/tags/ml/">ML</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
